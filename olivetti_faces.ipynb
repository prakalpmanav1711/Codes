{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0.30991736, 0.3677686 , 0.41735536, ..., 0.15289256, 0.16115703,\n",
       "         0.1570248 ],\n",
       "        [0.45454547, 0.47107437, 0.5123967 , ..., 0.15289256, 0.15289256,\n",
       "         0.15289256],\n",
       "        [0.3181818 , 0.40082645, 0.49173555, ..., 0.14049587, 0.14876033,\n",
       "         0.15289256],\n",
       "        ...,\n",
       "        [0.5       , 0.53305787, 0.607438  , ..., 0.17768595, 0.14876033,\n",
       "         0.19008264],\n",
       "        [0.21487603, 0.21900827, 0.21900827, ..., 0.57438016, 0.59090906,\n",
       "         0.60330576],\n",
       "        [0.5165289 , 0.46280992, 0.28099173, ..., 0.35950413, 0.3553719 ,\n",
       "         0.38429752]], dtype=float32),\n",
       " 'images': array([[[0.30991736, 0.3677686 , 0.41735536, ..., 0.37190083,\n",
       "          0.3305785 , 0.30578512],\n",
       "         [0.3429752 , 0.40495867, 0.43801653, ..., 0.37190083,\n",
       "          0.338843  , 0.3140496 ],\n",
       "         [0.3429752 , 0.41735536, 0.45041323, ..., 0.38016528,\n",
       "          0.338843  , 0.29752067],\n",
       "         ...,\n",
       "         [0.21487603, 0.20661157, 0.2231405 , ..., 0.15289256,\n",
       "          0.16528925, 0.17355372],\n",
       "         [0.20247933, 0.2107438 , 0.2107438 , ..., 0.14876033,\n",
       "          0.16115703, 0.16528925],\n",
       "         [0.20247933, 0.20661157, 0.20247933, ..., 0.15289256,\n",
       "          0.16115703, 0.1570248 ]],\n",
       " \n",
       "        [[0.45454547, 0.47107437, 0.5123967 , ..., 0.19008264,\n",
       "          0.18595041, 0.18595041],\n",
       "         [0.446281  , 0.48347107, 0.5206612 , ..., 0.21487603,\n",
       "          0.2107438 , 0.2107438 ],\n",
       "         [0.49586776, 0.5165289 , 0.53305787, ..., 0.20247933,\n",
       "          0.20661157, 0.20661157],\n",
       "         ...,\n",
       "         [0.77272725, 0.78099173, 0.7933884 , ..., 0.1446281 ,\n",
       "          0.1446281 , 0.1446281 ],\n",
       "         [0.77272725, 0.7768595 , 0.7892562 , ..., 0.13636364,\n",
       "          0.13636364, 0.13636364],\n",
       "         [0.7644628 , 0.7892562 , 0.78099173, ..., 0.15289256,\n",
       "          0.15289256, 0.15289256]],\n",
       " \n",
       "        [[0.3181818 , 0.40082645, 0.49173555, ..., 0.40082645,\n",
       "          0.3553719 , 0.30991736],\n",
       "         [0.30991736, 0.3966942 , 0.47933885, ..., 0.40495867,\n",
       "          0.37603307, 0.30165288],\n",
       "         [0.26859504, 0.34710744, 0.45454547, ..., 0.3966942 ,\n",
       "          0.37190083, 0.30991736],\n",
       "         ...,\n",
       "         [0.1322314 , 0.09917355, 0.08264463, ..., 0.13636364,\n",
       "          0.14876033, 0.15289256],\n",
       "         [0.11570248, 0.09504132, 0.0785124 , ..., 0.1446281 ,\n",
       "          0.1446281 , 0.1570248 ],\n",
       "         [0.11157025, 0.09090909, 0.0785124 , ..., 0.14049587,\n",
       "          0.14876033, 0.15289256]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.5       , 0.53305787, 0.607438  , ..., 0.28512397,\n",
       "          0.23966943, 0.21487603],\n",
       "         [0.49173555, 0.5413223 , 0.60330576, ..., 0.29752067,\n",
       "          0.20247933, 0.20661157],\n",
       "         [0.46694216, 0.55785125, 0.6198347 , ..., 0.29752067,\n",
       "          0.17768595, 0.18595041],\n",
       "         ...,\n",
       "         [0.03305785, 0.46280992, 0.5289256 , ..., 0.17355372,\n",
       "          0.17355372, 0.1694215 ],\n",
       "         [0.1570248 , 0.5247934 , 0.53305787, ..., 0.16528925,\n",
       "          0.1570248 , 0.18595041],\n",
       "         [0.45454547, 0.5206612 , 0.53305787, ..., 0.17768595,\n",
       "          0.14876033, 0.19008264]],\n",
       " \n",
       "        [[0.21487603, 0.21900827, 0.21900827, ..., 0.71487606,\n",
       "          0.71487606, 0.6942149 ],\n",
       "         [0.20247933, 0.20661157, 0.20661157, ..., 0.7107438 ,\n",
       "          0.7066116 , 0.6942149 ],\n",
       "         [0.2107438 , 0.20661157, 0.20661157, ..., 0.6859504 ,\n",
       "          0.69008267, 0.6942149 ],\n",
       "         ...,\n",
       "         [0.2644628 , 0.25619835, 0.2603306 , ..., 0.5413223 ,\n",
       "          0.57438016, 0.59090906],\n",
       "         [0.26859504, 0.2644628 , 0.26859504, ..., 0.56198347,\n",
       "          0.58264464, 0.59504133],\n",
       "         [0.27272728, 0.26859504, 0.27272728, ..., 0.57438016,\n",
       "          0.59090906, 0.60330576]],\n",
       " \n",
       "        [[0.5165289 , 0.46280992, 0.28099173, ..., 0.5785124 ,\n",
       "          0.5413223 , 0.60330576],\n",
       "         [0.5165289 , 0.45041323, 0.29338843, ..., 0.58264464,\n",
       "          0.553719  , 0.5785124 ],\n",
       "         [0.5165289 , 0.44214877, 0.29338843, ..., 0.59917355,\n",
       "          0.5785124 , 0.54545456],\n",
       "         ...,\n",
       "         [0.39256197, 0.41322315, 0.38842976, ..., 0.33471075,\n",
       "          0.37190083, 0.3966942 ],\n",
       "         [0.39256197, 0.38429752, 0.40495867, ..., 0.3305785 ,\n",
       "          0.35950413, 0.37603307],\n",
       "         [0.3677686 , 0.40495867, 0.3966942 , ..., 0.35950413,\n",
       "          0.3553719 , 0.38429752]]], dtype=float32),\n",
       " 'target': array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "        22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "        23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
       "        27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "        28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32,\n",
       "        32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35,\n",
       "        35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39]),\n",
       " 'DESCR': '.. _olivetti_faces_dataset:\\n\\nThe Olivetti faces dataset\\n--------------------------\\n\\n`This dataset contains a set of face images`_ taken between April 1992 and \\nApril 1994 at AT&T Laboratories Cambridge. The\\n:func:`sklearn.datasets.fetch_olivetti_faces` function is the data\\nfetching / caching function that downloads the data\\narchive from AT&T.\\n\\n.. _This dataset contains a set of face images: https://cam-orl.co.uk/facedatabase.html\\n\\nAs described on the original website:\\n\\n    There are ten different images of each of 40 distinct subjects. For some\\n    subjects, the images were taken at different times, varying the lighting,\\n    facial expressions (open / closed eyes, smiling / not smiling) and facial\\n    details (glasses / no glasses). All the images were taken against a dark\\n    homogeneous background with the subjects in an upright, frontal position \\n    (with tolerance for some side movement).\\n\\n**Data Set Characteristics:**\\n\\n    =================   =====================\\n    Classes                                40\\n    Samples total                         400\\n    Dimensionality                       4096\\n    Features            real, between 0 and 1\\n    =================   =====================\\n\\nThe image is quantized to 256 grey levels and stored as unsigned 8-bit \\nintegers; the loader will convert these to floating point values on the \\ninterval [0, 1], which are easier to work with for many algorithms.\\n\\nThe \"target\" for this database is an integer from 0 to 39 indicating the\\nidentity of the person pictured; however, with only 10 examples per class, this\\nrelatively small dataset is more interesting from an unsupervised or\\nsemi-supervised perspective.\\n\\nThe original dataset consisted of 92 x 112, while the version available here\\nconsists of 64x64 images.\\n\\nWhen using these images, please give credit to AT&T Laboratories Cambridge.\\n'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "faces = fetch_olivetti_faces()\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.714876</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.351240</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334711</td>\n",
       "      <td>0.289256</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.458678</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.223140</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.202479</td>\n",
       "      <td>0.276859</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392562</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>0.524793</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.603306</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.516529</td>\n",
       "      <td>0.462810</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.252066</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.359504</td>\n",
       "      <td>0.355372</td>\n",
       "      <td>0.384298</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
       "1    0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
       "2    0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
       "3    0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
       "4    0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  0.400826  0.495868  0.570248  0.632231  0.648760  0.640496  0.661157   \n",
       "396  0.367769  0.367769  0.351240  0.301653  0.247934  0.247934  0.367769   \n",
       "397  0.500000  0.533058  0.607438  0.628099  0.657025  0.632231  0.657025   \n",
       "398  0.214876  0.219008  0.219008  0.223140  0.210744  0.202479  0.276859   \n",
       "399  0.516529  0.462810  0.280992  0.252066  0.247934  0.367769  0.574380   \n",
       "\n",
       "            7         8         9  ...      4087      4088      4089  \\\n",
       "0    0.677686  0.690083  0.685950  ...  0.669421  0.652893  0.661157   \n",
       "1    0.702479  0.710744  0.702479  ...  0.157025  0.136364  0.148760   \n",
       "2    0.685950  0.702479  0.698347  ...  0.132231  0.181818  0.136364   \n",
       "3    0.404959  0.483471  0.516529  ...  0.636364  0.657025  0.685950   \n",
       "4    0.714876  0.723140  0.731405  ...  0.161157  0.177686  0.173554   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395  0.636364  0.665289  0.698347  ...  0.396694  0.264463  0.099174   \n",
       "396  0.512397  0.574380  0.628099  ...  0.334711  0.289256  0.285124   \n",
       "397  0.669421  0.673554  0.702479  ...  0.148760  0.152893  0.161157   \n",
       "398  0.400826  0.487603  0.549587  ...  0.392562  0.367769  0.409091   \n",
       "399  0.615702  0.661157  0.615702  ...  0.264463  0.293388  0.301653   \n",
       "\n",
       "         4090      4091      4092      4093      4094      4095  target  \n",
       "0    0.475207  0.132231  0.148760  0.152893  0.161157  0.157025       0  \n",
       "1    0.152893  0.152893  0.152893  0.152893  0.152893  0.152893       0  \n",
       "2    0.128099  0.148760  0.144628  0.140496  0.148760  0.152893       0  \n",
       "3    0.727273  0.743802  0.764463  0.752066  0.752066  0.739669       0  \n",
       "4    0.177686  0.177686  0.177686  0.177686  0.173554  0.173554       0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "395  0.181818  0.243802  0.247934  0.161157  0.157025  0.136364      39  \n",
       "396  0.338843  0.404959  0.458678  0.487603  0.512397  0.549587      39  \n",
       "397  0.161157  0.173554  0.157025  0.177686  0.148760  0.190083      39  \n",
       "398  0.479339  0.524793  0.545455  0.574380  0.590909  0.603306      39  \n",
       "399  0.293388  0.322314  0.322314  0.359504  0.355372  0.384298      39  \n",
       "\n",
       "[400 rows x 4097 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "faces_df = pd.DataFrame(faces[\"data\"])\n",
    "faces_df[\"target\"] = faces[\"target\"]\n",
    "faces_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = faces_df.drop(\"target\",axis=1)\n",
    "Y = faces_df[\"target\"]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model = SVC().fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier().fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds = np.array(model.predict(X_test))\n",
    "np.mean(Y_preds==Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.01, 0.03, 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  ,\n",
       "        0.03, 0.01, 0.02, 0.01, 0.01, 0.02, 0.  , 0.  , 0.01, 0.59, 0.  ,\n",
       "        0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.04, 0.03, 0.02, 0.01, 0.02,\n",
       "        0.  , 0.05, 0.  , 0.01, 0.  , 0.01, 0.  ],\n",
       "       [0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.03, 0.03,\n",
       "        0.  , 0.02, 0.  , 0.01, 0.  , 0.  , 0.65, 0.02, 0.04, 0.  , 0.12,\n",
       "        0.01, 0.  , 0.01, 0.  , 0.  , 0.03, 0.  ],\n",
       "       [0.03, 0.02, 0.03, 0.42, 0.01, 0.02, 0.01, 0.01, 0.01, 0.05, 0.  ,\n",
       "        0.01, 0.09, 0.01, 0.  , 0.01, 0.  , 0.05, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.05, 0.  , 0.03, 0.01, 0.  , 0.02, 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.01, 0.01, 0.  , 0.03, 0.  , 0.05],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.7 ,\n",
       "        0.  , 0.01, 0.01, 0.01, 0.  , 0.01, 0.05, 0.  , 0.06, 0.  , 0.01,\n",
       "        0.09, 0.  , 0.  , 0.02, 0.  , 0.02, 0.  ],\n",
       "       [0.02, 0.01, 0.01, 0.01, 0.  , 0.  , 0.  , 0.02, 0.02, 0.39, 0.  ,\n",
       "        0.01, 0.01, 0.  , 0.04, 0.02, 0.02, 0.  , 0.  , 0.05, 0.01, 0.02,\n",
       "        0.  , 0.02, 0.06, 0.02, 0.06, 0.01, 0.01, 0.05, 0.01, 0.02, 0.  ,\n",
       "        0.  , 0.01, 0.  , 0.03, 0.01, 0.02, 0.01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score = cross_val_score(model,X,Y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "model.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400000000000001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.27, 0.  , 0.01, ..., 0.11, 0.01, 0.01],\n",
       "        [0.01, 0.02, 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "        [0.03, 0.  , 0.  , ..., 0.  , 0.  , 0.01],\n",
       "        ...,\n",
       "        [0.01, 0.04, 0.1 , ..., 0.01, 0.01, 0.01],\n",
       "        [0.05, 0.01, 0.04, ..., 0.02, 0.  , 0.  ],\n",
       "        [0.  , 0.01, 0.  , ..., 0.  , 0.07, 0.01]]),\n",
       " 80)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "probs[10:], len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.02, 0.  , 0.01, 0.03, 0.  , 0.  , 0.01, 0.03])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_positive = probs[:,1]\n",
    "prob_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[1;32m----> 2\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_positive\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ratee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[0;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    906\u001b[0m ):\n\u001b[0;32m    907\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \n\u001b[0;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ratee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:749\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    747\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    752\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "379523d68ddbea1caa2d84d2e0b45a67bae01a8b95f4b6debf29773e00031407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
